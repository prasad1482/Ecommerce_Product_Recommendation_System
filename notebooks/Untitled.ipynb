{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d351a08e-5fbd-40f6-b6b6-fbc30dde2669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e05d2ca3-1acc-424d-9e2b-ada4058310ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('C:\\machihe learning\\Projects\\Recomendation system\\src\\products.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c45548f4-4ee0-4eed-aa6a-1ac48ed5224c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_category</th>\n",
       "      <th>product_description</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Follow Power</td>\n",
       "      <td>Toys &amp; Games</td>\n",
       "      <td>Upon improve must put. Billion network left ac...</td>\n",
       "      <td>350.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>International Mr</td>\n",
       "      <td>Toys &amp; Games</td>\n",
       "      <td>War three toward charge. Society event into me...</td>\n",
       "      <td>81.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>However Fish</td>\n",
       "      <td>Books</td>\n",
       "      <td>Arrive investment stage firm toward stay. Prod...</td>\n",
       "      <td>495.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id      product_name product_category  \\\n",
       "0           1      Follow Power     Toys & Games   \n",
       "1           2  International Mr     Toys & Games   \n",
       "2           3      However Fish            Books   \n",
       "\n",
       "                                 product_description   price  \n",
       "0  Upon improve must put. Billion network left ac...  350.24  \n",
       "1  War three toward charge. Society event into me...   81.60  \n",
       "2  Arrive investment stage firm toward stay. Prod...  495.15  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ab197fd-9f25-4e97-b78a-c3f2ee44e915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "try:\n",
    "    interactions_df = pd.read_csv('C:\\\\machihe learning\\\\Projects\\\\Recomendation system\\\\src\\\\interactions.csv')\n",
    "    products_df = pd.read_csv('C:\\\\machihe learning\\\\Projects\\\\Recomendation system\\\\src\\\\products.csv')\n",
    "    users_df = pd.read_csv('C:\\\\machihe learning\\\\Projects\\\\Recomendation system\\\\src\\\\users.csv')\n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: One or more CSV files not found. Make sure they are in the correct directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30af6e36-5bb8-48b0-abea-6f3f148d30e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interactions DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   user_id     100000 non-null  int64 \n",
      " 1   product_id  100000 non-null  int64 \n",
      " 2   rating      100000 non-null  int64 \n",
      " 3   timestamp   100000 non-null  object\n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# --- Perform initial inspection ---\n",
    "print(\"\\nInteractions DataFrame Info:\")\n",
    "interactions_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06d9036f-e2b9-4dd2-a2dc-e7966fde906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Merge the DataFrames ---\n",
    "# We'll merge interactions with products to get product details\n",
    "merged_df = pd.merge(interactions_df, products_df, on='product_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4c09d10-03b0-47b1-a539-542ba26d07af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we'll merge with users to get user details\n",
    "final_df = pd.merge(merged_df, users_df, on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4242b7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_with_ratings_df = final_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68fc2efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_df saved to data/processed/final_df.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "final_df.to_csv('data/processed/final_df.csv', index=False)\n",
    "print('final_df saved to data/processed/final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2e90625-7238-4f50-bea3-5a56030231ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Merged DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   user_id              100000 non-null  int64  \n",
      " 1   product_id           100000 non-null  int64  \n",
      " 2   rating               100000 non-null  int64  \n",
      " 3   timestamp            100000 non-null  object \n",
      " 4   product_name         100000 non-null  object \n",
      " 5   product_category     100000 non-null  object \n",
      " 6   product_description  100000 non-null  object \n",
      " 7   price                100000 non-null  float64\n",
      " 8   signup_date          100000 non-null  object \n",
      "dtypes: float64(1), int64(3), object(5)\n",
      "memory usage: 6.9+ MB\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFinal Merged DataFrame Info:\")\n",
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0c11580-e28b-446c-98d8-1b0ee5ab15eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "final_df.to_csv('data/processed/final_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a43f0d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_category</th>\n",
       "      <th>product_description</th>\n",
       "      <th>price</th>\n",
       "      <th>signup_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>279</td>\n",
       "      <td>1448</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 07:47:50</td>\n",
       "      <td>Full Act</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Including experience just side. Meet factor in...</td>\n",
       "      <td>132.54</td>\n",
       "      <td>2023-12-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>385</td>\n",
       "      <td>1906</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-12 19:14:44</td>\n",
       "      <td>Medical Catch</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Test former major all. Once support political....</td>\n",
       "      <td>361.64</td>\n",
       "      <td>2024-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>740</td>\n",
       "      <td>2239</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-05-11 08:04:50</td>\n",
       "      <td>Machine Exactly</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Himself citizen mother. Age born south already...</td>\n",
       "      <td>340.67</td>\n",
       "      <td>2021-08-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  product_id  rating            timestamp     product_name  \\\n",
       "0      279        1448       1  2024-01-01 07:47:50         Full Act   \n",
       "1      385        1906       1  2024-01-12 19:14:44    Medical Catch   \n",
       "2      740        2239       1  2024-05-11 08:04:50  Machine Exactly   \n",
       "\n",
       "  product_category                                product_description   price  \\\n",
       "0          Apparel  Including experience just side. Meet factor in...  132.54   \n",
       "1           Sports  Test former major all. Once support political....  361.64   \n",
       "2           Sports  Himself citizen mother. Age born south already...  340.67   \n",
       "\n",
       "  signup_date  \n",
       "0  2023-12-08  \n",
       "1  2024-05-23  \n",
       "2  2021-08-29  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7576da6-c546-4270-ae2e-f22bf237da36",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a2b8282-d3f0-4512-bcf4-ddc7d08aec46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-surprise in c:\\machihe learning\\projects\\recomendation system\\recom39\\lib\\site-packages (1.1.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\machihe learning\\projects\\recomendation system\\recom39\\lib\\site-packages (from scikit-surprise) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\machihe learning\\projects\\recomendation system\\recom39\\lib\\site-packages (from scikit-surprise) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\machihe learning\\projects\\recomendation system\\recom39\\lib\\site-packages (from scikit-surprise) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 25.2 is available.\n",
      "You should consider upgrading via the 'c:\\machihe learning\\Projects\\Recomendation system\\recom39\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c861f7ee-84b3-42a9-b253-f7fa3494ef2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61b27861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\machihe learning\\Projects\\Recomendation system\\notebooks\n"
     ]
    }
   ],
   "source": [
    "!cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3efaf55c-f548-43b9-aaab-bea34c896885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed data\n",
    "purchases_df = pd.read_csv('data/processed/final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba9b5afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62af4df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DataFrame into the Surprise Dataset format\n",
    "data = Dataset.load_from_df(purchases_df[['user_id', 'product_id', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea9040b",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57c4b8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "trainset = data.build_full_trainset()\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4467d79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Make a prediction for a specific user ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab1c35fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted rating for user 279 on product 1: 1.8301754026202681\n"
     ]
    }
   ],
   "source": [
    "# Let's pick a random user to make a prediction for.\n",
    "user_id_to_predict = purchases_df['user_id'].iloc[0] # Get the first user from the DataFrame\n",
    "product_id_to_predict = products_df[~products_df['product_id'].isin(\n",
    "    purchases_df[purchases_df['user_id'] == user_id_to_predict]['product_id']\n",
    ")]['product_id'].iloc[0]\n",
    "\n",
    "# Predict the rating the user would give to the product\n",
    "prediction = model.predict(user_id_to_predict, product_id_to_predict)\n",
    "\n",
    "print(f\"\\nPredicted rating for user {user_id_to_predict} on product {product_id_to_predict}: {prediction.est}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5efb08f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 recommended product IDs for user 279:\n",
      "[2776, 2747, 4097, 3751, 597, 3252, 824, 3680, 4604, 1800]\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Get Top N recommendations for a user ---\n",
    "# This is a more practical application.\n",
    "def get_top_n_recommendations(model, user_id, all_products, k=10):\n",
    "    # Get products the user has NOT purchased\n",
    "    user_purchased_items = purchases_df[purchases_df['user_id'] == user_id]['product_id']\n",
    "    unseen_products = [product for product in all_products if product not in user_purchased_items.values]\n",
    "\n",
    "    # Predict ratings for all unseen products\n",
    "    predictions = [model.predict(user_id, product_id) for product_id in unseen_products]\n",
    "\n",
    "    # Sort the predictions by estimated rating\n",
    "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "\n",
    "    # Get the top k products\n",
    "    top_k_products = predictions[:k]\n",
    "    \n",
    "    return [pred.iid for pred in top_k_products]\n",
    "\n",
    "# Get all unique product IDs\n",
    "all_products = products_df['product_id'].unique()\n",
    "\n",
    "top_recommendations = get_top_n_recommendations(model, user_id_to_predict, all_products)\n",
    "print(f\"\\nTop 10 recommended product IDs for user {user_id_to_predict}:\")\n",
    "print(top_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ff9af7",
   "metadata": {},
   "source": [
    "# Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0371d518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b60fbcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x2250a386b50>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Train the model on the training set ---\n",
    "model = SVD()\n",
    "model.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccb8b0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Make predictions on the testing set ---\n",
    "predictions = model.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13955bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.3907\n",
      "The model's RMSE on the test set is: 1.3906842219969462\n"
     ]
    }
   ],
   "source": [
    "rmse = accuracy.rmse(predictions)\n",
    "print(f\"The model's RMSE on the test set is: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15026d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_top_n(predictions, n=10):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\"\"\"\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "    return top_n\n",
    "\n",
    "top_n = get_top_n(predictions, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f220c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique product IDs for recommendations\n",
    "all_products = products_df['product_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efbb338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a user to make recommendations for (e.g., the first user in the DataFrame)\n",
    "user_id_to_predict = interactions_with_ratings_df['user_id'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0976aa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 10 recommended product IDs\n",
    "top_recommendations = get_top_n(model.test(trainset.build_anti_testset()), n=10)[user_id_to_predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cef577cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 recommended product IDs and estimated ratings for user 279:\n",
      "Product ID: 4612, Estimated Rating: 3.2568\n",
      "Product ID: 134, Estimated Rating: 3.1847\n",
      "Product ID: 581, Estimated Rating: 3.1395\n",
      "Product ID: 4614, Estimated Rating: 3.1010\n",
      "Product ID: 1894, Estimated Rating: 3.0749\n",
      "Product ID: 4101, Estimated Rating: 3.0748\n",
      "Product ID: 4711, Estimated Rating: 3.0653\n",
      "Product ID: 2488, Estimated Rating: 3.0471\n",
      "Product ID: 1093, Estimated Rating: 2.9975\n",
      "Product ID: 4306, Estimated Rating: 2.9887\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nTop 10 recommended product IDs and estimated ratings for user {user_id_to_predict}:\")\n",
    "for product_id, est_rating in top_recommendations:\n",
    "    print(f\"Product ID: {product_id}, Estimated Rating: {est_rating:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c04971c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating Precision and Recall...\n",
      "Average Precision@10: 0.0000\n",
      "Average Recall@10: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def precision_recall_at_k(predictions, k=10, threshold=4):\n",
    "    \"\"\"\n",
    "    Return precision and recall at k metrics for each user.\n",
    "    'threshold' is the rating above which an item is considered 'relevant'\n",
    "    for the user. We'll set it to 4 to consider only 'purchase' events as relevant.\n",
    "    \"\"\"\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = defaultdict(float)\n",
    "    recalls = defaultdict(float)\n",
    "    \n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_relevant = sum(1 for _, true_r in user_ratings if true_r >= threshold)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum(1 for est, _ in user_ratings[:k] if est >= threshold)\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(1 for est, true_r in user_ratings[:k] if true_r >= threshold and est >= threshold)\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "        recalls[uid] = n_rel_and_rec_k / n_relevant if n_relevant != 0 else 0\n",
    "\n",
    "    return precisions, recalls\n",
    "\n",
    "# Now, add this to your main script after you get the 'predictions'\n",
    "print(\"\\nCalculating Precision and Recall...\")\n",
    "precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=4)\n",
    "\n",
    "# Average precision and recall\n",
    "avg_precision = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "avg_recall = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "\n",
    "print(f\"Average Precision@10: {avg_precision:.4f}\")\n",
    "print(f\"Average Recall@10: {avg_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72b9a2a",
   "metadata": {},
   "source": [
    "# Hyperparameter tunning using grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0802f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\machihe learning\\Projects\\Recomendation system\\notebooks\n"
     ]
    }
   ],
   "source": [
    "!cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b046e8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "\n",
      "Starting GridSearchCV for SVD model...\n",
      "Best RMSE score: 1.3658\n",
      "Best hyperparameters: {'n_epochs': 20, 'lr_all': 0.005, 'reg_all': 0.05}\n",
      "\n",
      "Calculating Final Precision and Recall...\n",
      "Average Precision@10 (Tuned Model): 0.0000\n",
      "Average Recall@10 (Tuned Model): 0.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split, GridSearchCV\n",
    "from surprise import accuracy\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "# --- 1. Load and Prepare the Data ---\n",
    "try:\n",
    "    # Use a relative path that works on any machine\n",
    "    interactions_df = pd.read_csv('C:\\machihe learning\\Projects\\Recomendation system\\src\\interactions.csv')\n",
    "    interactions_df['rating'] = pd.to_numeric(interactions_df['rating'])\n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The 'interactions.csv' file not found. Make sure it is in the same directory as this script.\")\n",
    "\n",
    "# --- 2. Data Formatting for Surprise Library ---\n",
    "reader = Reader(rating_scale=(1, 5)) \n",
    "data = Dataset.load_from_df(interactions_df[['user_id', 'product_id', 'rating']], reader)\n",
    "\n",
    "# --- 3. Hyperparameter Tuning ---\n",
    "# 'cv=5' means we will use 5-fold cross-validation\n",
    "# 'n_jobs=-1' uses all available CPU cores for faster execution\n",
    "param_grid = {\n",
    "    'n_epochs': [20, 30],\n",
    "    'lr_all': [0.005, 0.01],\n",
    "    'reg_all': [0.02, 0.05]\n",
    "}\n",
    "\n",
    "print(\"\\nStarting GridSearchCV for SVD model...\")\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=5, n_jobs=-1)\n",
    "gs.fit(data)\n",
    "\n",
    "best_params = gs.best_params['rmse']\n",
    "print(f\"Best RMSE score: {gs.best_score['rmse']:.4f}\")\n",
    "print(f\"Best hyperparameters: {best_params}\")\n",
    "\n",
    "# --- 4. Final Model Training and Evaluation with Best Parameters ---\n",
    "# Split the data into a training set and a testing set for evaluation\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use the best hyperparameters found by GridSearchCV\n",
    "final_model = SVD(\n",
    "    n_epochs=best_params['n_epochs'],\n",
    "    lr_all=best_params['lr_all'],\n",
    "    reg_all=best_params['reg_all']\n",
    ")\n",
    "\n",
    "# Train the final model on the training set\n",
    "final_model.fit(trainset)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "predictions = final_model.test(testset)\n",
    "\n",
    "# --- 5. Final Evaluation with Precision and Recall ---\n",
    "def precision_recall_at_k(predictions, k=10, threshold=4):\n",
    "    \"\"\"\n",
    "    Return precision and recall at k metrics for each user.\n",
    "    \"\"\"\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = defaultdict(float)\n",
    "    recalls = defaultdict(float)\n",
    "    \n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        \n",
    "        n_relevant = sum(1 for _, true_r in user_ratings if true_r >= threshold)\n",
    "        n_rec_k = k\n",
    "        n_rel_and_rec_k = sum(1 for est, true_r in user_ratings[:k] if est >= threshold and true_r >= threshold)\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "        recalls[uid] = n_rel_and_rec_k / n_relevant if n_relevant != 0 else 0\n",
    "\n",
    "    return precisions, recalls\n",
    "\n",
    "print(\"\\nCalculating Final Precision and Recall...\")\n",
    "precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=4)\n",
    "\n",
    "avg_precision = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "avg_recall = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "\n",
    "print(f\"Average Precision@10 (Tuned Model): {avg_precision:.4f}\")\n",
    "print(f\"Average Recall@10 (Tuned Model): {avg_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba679629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating Final Precision and Recall...\n",
      "Average Precision@10 (Tuned Model): 0.0008\n",
      "Average Recall@10 (Tuned Model): 0.0010\n"
     ]
    }
   ],
   "source": [
    "# --- Correctly instantiate the final model with best params ---\n",
    "final_model = SVD(\n",
    "    n_epochs=20,\n",
    "    lr_all=0.005,\n",
    "    reg_all=0.05\n",
    ")\n",
    "\n",
    "# --- Split, Train, and Predict ---\n",
    "reader = Reader(rating_scale=(1, 5)) \n",
    "data = Dataset.load_from_df(interactions_df[['user_id', 'product_id', 'rating']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "final_model.fit(trainset)\n",
    "predictions = final_model.test(testset)\n",
    "\n",
    "# --- Final Evaluation with Corrected Precision and Recall Logic ---\n",
    "def precision_recall_at_k(predictions, k=10, threshold=3):\n",
    "    \"\"\"\n",
    "    Return precision and recall at k metrics for each user.\n",
    "    Lowering the threshold to 3 to include 'add to cart' events.\n",
    "    \"\"\"\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = defaultdict(float)\n",
    "    recalls = defaultdict(float)\n",
    "    \n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        \n",
    "        n_relevant = sum(1 for _, true_r in user_ratings if true_r >= threshold)\n",
    "        n_rec_k = k\n",
    "        n_rel_and_rec_k = sum(1 for est, true_r in user_ratings[:k] if est >= threshold and true_r >= threshold)\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "        recalls[uid] = n_rel_and_rec_k / n_relevant if n_relevant != 0 else 0\n",
    "\n",
    "    return precisions, recalls\n",
    "\n",
    "print(\"\\nCalculating Final Precision and Recall...\")\n",
    "precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=3)\n",
    "\n",
    "avg_precision = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "avg_recall = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "\n",
    "print(f\"Average Precision@10 (Tuned Model): {avg_precision:.4f}\")\n",
    "print(f\"Average Recall@10 (Tuned Model): {avg_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ea7cb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved to: data\\processed\\final_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# --- Save the trained model to a file ---\n",
    "# This is a critical production-ready step\n",
    "from surprise import dump\n",
    "model_path = os.path.join('data', 'processed', 'final_model.pkl')\n",
    "dump.dump(model_path, algo=final_model)\n",
    "print(f\"Final model saved to: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "536c01fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create a Cold-Start Fallback (Popularity-Based Recommender) ---\n",
    "# Group by product and count interactions to find the most popular products\n",
    "popular_products = interactions_df.groupby('product_id')['rating'].count().sort_values(ascending=False).head(10).index.tolist()\n",
    "popular_products_info = products_df[products_df['product_id'].isin(popular_products)]['product_name'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c5eb322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(user_id, model, trainset, all_products, top_n=10):\n",
    "    # Check if the user is in our training data\n",
    "    if trainset.knows_user(user_id):\n",
    "        print(\"User found in training data. Using collaborative filtering.\")\n",
    "        \n",
    "        # Get products the user has NOT rated by checking all products\n",
    "        # This is a more robust way to handle unseen items\n",
    "        unseen_products = []\n",
    "        for product_id in all_products:\n",
    "            if not trainset.knows_item(product_id) or not trainset.knows_user(user_id) or not trainset.knows_item(trainset.to_inner_iid(product_id)) or (user_id, product_id) not in trainset._inner_id_to_raw_id_item[trainset.to_inner_iid(product_id)]:\n",
    "                unseen_products.append(product_id)\n",
    "\n",
    "        # Get predictions for unseen items\n",
    "        predictions = [model.predict(user_id, product_id) for product_id in unseen_products]\n",
    "        predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "        top_recommendations = [pred.iid for pred in predictions[:top_n]]\n",
    "\n",
    "    else:\n",
    "        # Fallback to popularity-based for new users\n",
    "        print(\"New user. Using popularity-based recommendations.\")\n",
    "        # Assuming you've already calculated 'popular_products' from the full dataset\n",
    "        # popular_products = interactions_df.groupby('product_id')['rating'].count().sort_values(ascending=False).head(10).index.tolist()\n",
    "        top_recommendations = popular_products\n",
    "\n",
    "    return top_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6ba95697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Test the recommendation function ---\n",
    "all_products_ids = products_df['product_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "518d6df6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_recommendations() missing 1 required positional argument: 'all_products'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 1. Get recommendations for a known user (e.g., user 1)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m known_user_id \u001b[38;5;241m=\u001b[39m interactions_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m recs_known_user \u001b[38;5;241m=\u001b[39m \u001b[43mget_recommendations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mknown_user_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_products_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRecommendations for known user \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mknown_user_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecs_known_user\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: get_recommendations() missing 1 required positional argument: 'all_products'"
     ]
    }
   ],
   "source": [
    "# 1. Get recommendations for a known user (e.g., user 1)\n",
    "known_user_id = interactions_df['user_id'].iloc[0]\n",
    "recs_known_user = get_recommendations(known_user_id, final_model, all_products_ids)\n",
    "print(f\"\\nRecommendations for known user {known_user_id}: {recs_known_user}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b0e563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recom39 (3.9.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
